{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Q2: Write a python program to scrape data for “Data Scientist” Job position in\n",
    "“Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required libraries \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from selenium.webdriver.support.ui import Select \n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the chrome driver & URL to be scrapped \n",
    "driver= webdriver.Chrome(r\"C:\\Users\\arkay\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")\n",
    "url='https://www.naukri.com/data-scientist-jobs-in-bangalore?k=%E2%80%9Cdata%20scientist&l=bangalore'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "job=[]\n",
    "company=[]\n",
    "location=[]\n",
    "jobdescription=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_tags=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div[1]/a\")\n",
    "for i in j_tags:\n",
    "    dataset=i.text\n",
    "    job.append(dataset)\n",
    "\n",
    "c_tags=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div[1]/div/a[1]\")\n",
    "for i in c_tags:\n",
    "    dataset=i.text\n",
    "    company.append(dataset)\n",
    "\n",
    "l_tags=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div[1]/ul/li[3]/span\")\n",
    "for i in l_tags:\n",
    "    dataset=i.text\n",
    "    location.append(dataset)\n",
    "    \n",
    "jd_tags=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[2]\")\n",
    "for i in jd_tags:\n",
    "    dataset=i.text\n",
    "    jobdescription.append(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Jobdescription</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior / Lead Data Scientist</td>\n",
       "      <td>TVS CREDIT SERVICES LIMITED</td>\n",
       "      <td>Chennai, Pune, Bengaluru</td>\n",
       "      <td>Experience in working with large data sets and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sr . Data Scientist</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>A bachelor s degree in engineering or science ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sr. Data Scientist</td>\n",
       "      <td>NetApp</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>A bachelor s degree in engineering or science ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Role Brief As a Senior data scientist you will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Advanced Architect - Data Scientist</td>\n",
       "      <td>Mphasis Limited</td>\n",
       "      <td>Bengaluru</td>\n",
       "      <td>Experience working with enterprise architectur...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title                      Company  \\\n",
       "0         Senior / Lead Data Scientist  TVS CREDIT SERVICES LIMITED   \n",
       "1                  Sr . Data Scientist                       NetApp   \n",
       "2                   Sr. Data Scientist                       NetApp   \n",
       "3                Senior Data Scientist            Fractal Analytics   \n",
       "4  Advanced Architect - Data Scientist              Mphasis Limited   \n",
       "\n",
       "                   Location                                     Jobdescription  \n",
       "0  Chennai, Pune, Bengaluru  Experience in working with large data sets and...  \n",
       "1                 Bengaluru  A bachelor s degree in engineering or science ...  \n",
       "2                 Bengaluru  A bachelor s degree in engineering or science ...  \n",
       "3                 Bengaluru  Role Brief As a Senior data scientist you will...  \n",
       "4                 Bengaluru  Experience working with enterprise architectur...  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs=pd.DataFrame({})\n",
    "jobs['Title']=job\n",
    "jobs['Company']=company\n",
    "jobs['Location']=location\n",
    "jobs['Jobdescription']=jobdescription\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing the chrome driver & URL to be scrapped \n",
    "driver= webdriver.Chrome(r\"C:\\Users\\arkay\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")\n",
    "url='https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath(\"//*[@id='qsb-keyword-sugg']\").send_keys('Data Scientist')\n",
    "driver.find_element_by_xpath(\"//*[@id='root']/div[3]/div[2]/section/div/form/div[3]/button\").click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "job=[]\n",
    "company=[]\n",
    "location=[]\n",
    "jobdesc=[]\n",
    "exp=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "j_tags=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div[1]/a\")\n",
    "for i in j_tags:\n",
    "    dataset=i.text\n",
    "    job.append(dataset)\n",
    "\n",
    "c_tags=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div/div/a\")\n",
    "for i in c_tags:\n",
    "    dataset=i.text\n",
    "    company.append(dataset)\n",
    "    \n",
    "l_tags=driver.find_elements_by_xpath(\"//*[@id='root']/div[3]/div[2]/section[2]/div[2]/article/div[1]/div[1]/ul/li[3]/span\")\n",
    "for i in l_tags:\n",
    "    dataset=i.text\n",
    "    location.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(location)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q3. You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company_name,\n",
    "experience_required.\n",
    "The location filter to be used is “Delhi/NCR”\n",
    "The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "\n",
    ".\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\arkay\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")\n",
    "url=\"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(5)\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc=driver.find_element_by_xpath(\"//span[@title='Delhi/NCR']\")\n",
    "loc.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-7 Yrs</td>\n",
       "      <td>Sharp Coating pvt. ltd.</td>\n",
       "      <td>Faridabad</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required             company_name job_location     job_title\n",
       "0             2-7 Yrs  Sharp Coating pvt. ltd.    Faridabad  Data Analyst"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "\n",
    "Brand\n",
    "Product Description\n",
    "Price\n",
    "Discount To scrape the data you have to go through following steps:\n",
    "Go to flipkart webpage by url https://www.flipkart.com/\n",
    "Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver= webdriver.Chrome(r\"C:\\Users\\arkay\\Downloads\\chromedriver_win32 (1)\\chromedriver.exe\")\n",
    "url=\"https://www.flipkart.com/search?q=sunglasses&otracker=search&otracker1=search&marketplace=FLIPKART&as-show=off&as=off\"\n",
    "driver.get(url)\n",
    "driver.maximize_window()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(0,3):#for loop for scrapping 3 page\n",
    "    brands=driver.find_elements_by_class_name('_2B_pmu')#scraping brands name by class name='_2B_pmu'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_class_name('_2mylT6')#scraping description by class name = '_2mylT6'\n",
    "    for i in desc:\n",
    "        description.append(i.get_attribute('title'))#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_1vC4OE']\")# scraping the price from the xpath\n",
    "    for i in prices[:40]:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='VGWI6T']\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Brand, Description, Price, Discount]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "#printing dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
